# Logstash 8.0 Configuration for Matter Platform
# Purpose: Enterprise log aggregation and security monitoring

# Global settings
input {
  # Filebeat input for application logs
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify_mode => "force_peer"
    client_inactivity_timeout => 60
    include_codec_tag => true
  }

  # TCP input for system logs
  tcp {
    port => 5000
    codec => json
    ssl_enable => true
    ssl_cert => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify => true
  }

  # HTTP input for custom application metrics
  http {
    port => 8080
    codec => json
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    auth_basic => true
    auth_basic_userlist => "/etc/logstash/auth/users"
  }
}

filter {
  # Add environment metadata
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT}"
      "datacenter" => "${DATACENTER}"
      "service_version" => "${SERVICE_VERSION}"
    }
  }

  # Grok pattern matching for structured logging
  grok {
    match => {
      "message" => [
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} \[%{DATA:service}\] %{DATA:trace_id} - %{GREEDYDATA:log_message}",
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} %{DATA:class}: %{GREEDYDATA:log_message}"
      ]
    }
    overwrite => ["message"]
    tag_on_failure => ["_grokparsefailure"]
  }

  # Date handling with timezone normalization
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    timezone => "UTC"
  }

  # GeoIP enrichment for security monitoring
  geoip {
    source => "client_ip"
    target => "geoip"
    fields => ["city_name", "country_name", "location"]
    database => "/etc/logstash/geoip/GeoLite2-City.mmdb"
  }

  # Security event detection
  if [log_level] == "ERROR" or [log_level] == "FATAL" {
    ruby {
      code => '
        event.set("security_alert", true)
        event.set("alert_severity", event.get("log_level") == "FATAL" ? "high" : "medium")
      '
    }
  }

  # User activity audit trail
  if [type] == "user_activity" {
    aggregate {
      task_id => "%{user_id}"
      code => "
        map['activity_count'] ||= 0
        map['activity_count'] += 1
        event.set('activity_sequence', map['activity_count'])
      "
      timeout => 3600
    }
  }

  # Performance metrics processing
  if [type] == "performance_metric" {
    ruby {
      code => '
        event.set("performance_score", 
          event.get("response_time").to_f < 1000 ? "good" : 
          event.get("response_time").to_f < 3000 ? "warning" : "critical"
        )
      '
    }
  }
}

output {
  # Primary Elasticsearch output
  elasticsearch {
    hosts => ["${ES_HOSTS}"]
    ssl => true
    ssl_certificate_verification => true
    cacert => "/etc/logstash/certs/ca.crt"
    user => "${ES_USER}"
    password => "${ES_PASSWORD}"
    
    # Index management
    index => "matter-logs-%{+YYYY.MM.dd}"
    template_name => "matter-logs"
    template_overwrite => true
    
    # Bulk operation settings
    bulk_max_size => 5000
    bulk_max_bytes => 10485760  # 10MB
    
    # Retry configuration
    retry_initial_interval => 2
    retry_max_interval => 64
    retry_on_conflict => 3
    
    # Document management
    document_id => "%{[@metadata][id]}"
    routing => "%{[@metadata][routing]}"
    
    # Pipeline settings
    pipeline => "matter-logs-pipeline"
    
    # ILM settings
    ilm_enabled => true
    ilm_rollover_alias => "matter-logs"
    ilm_pattern => "{now/d}-000001"
    ilm_policy => "matter-logs-policy"
  }

  # Dead letter queue for failed events
  if "_grokparsefailure" in [tags] or "_dateparsefailure" in [tags] {
    elasticsearch {
      hosts => ["${ES_HOSTS}"]
      ssl => true
      cacert => "/etc/logstash/certs/ca.crt"
      user => "${ES_USER}"
      password => "${ES_PASSWORD}"
      index => "matter-logs-failed-%{+YYYY.MM.dd}"
      pipeline => "matter-logs-dlq-pipeline"
    }
  }

  # Security alerts output
  if [security_alert] == true {
    elasticsearch {
      hosts => ["${ES_HOSTS}"]
      ssl => true
      cacert => "/etc/logstash/certs/ca.crt"
      user => "${ES_USER}"
      password => "${ES_PASSWORD}"
      index => "matter-security-alerts-%{+YYYY.MM.dd}"
      pipeline => "matter-security-pipeline"
    }
  }
}